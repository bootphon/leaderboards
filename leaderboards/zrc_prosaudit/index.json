{
    "last_modified": "2023-02-24T14:03:47.969888",
    "data": [
        {
            "model_id": "gslm23a",
            "submission_id": "GSLM",
            "index": 0,
            "submission_date": "2023-02-24T14:03:41.697021",
            "submitted_by": "admin",
            "description": "HuBert + Kmeans + Transformer. \nRefer to de Seyssel et al (2023) for more details. \nModel used from : K. Lakhotia, E. Kharitonov, W.-N. Hsu, Y. Adi, A. Polyak, B. Bolte, T.-A. Nguyen, J. Copet, A. Baevski, A. Mohamed et al., \n\u201cOn generative spoken language modeling from raw audio,\u201d Transactions of the Association for Computational Linguistics, vol. 9, pp. 1336\u20131354, 2021\"\n",
            "publication": {
                "author_short": "GSLM",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "LibriLight clean 6k",
                "benchmarks": [],
                "gpu_budget": "-",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.5878,
                        "n": 262,
                        "std": 0.4932
                    },
                    "test": {
                        "score": 0.5813,
                        "n": 2355,
                        "std": 0.4934
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.5328,
                        "n": 259,
                        "std": 0.4999
                    },
                    "test": {
                        "score": 0.5412,
                        "n": 2330,
                        "std": 0.4984
                    }
                }
            },
            "extras": null
        },
        {
            "model_id": "gslm23b",
            "submission_id": "GSLM_dedup",
            "index": 1,
            "submission_date": "2023-02-24T14:03:41.784490",
            "submitted_by": "admin",
            "description": "HuBert + Kmeans (deduplicated) + Transformer. \nRefer to de Seyssel et al (2023) for more details.\nModel used from : K. Lakhotia, E. Kharitonov, W.-N. Hsu, Y. Adi, A. Polyak, B. Bolte, T.-A. Nguyen, J. Copet, A. Baevski, A. Mohamed et al., \n\u201cOn generative spoken language modeling from raw audio,\u201d Transactions of the Association for Computational Linguistics, vol. 9, pp. 1336\u20131354, 2021\n",
            "publication": {
                "author_short": "GSLM deduplicated",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "LibriLight clean 6k",
                "benchmarks": [],
                "gpu_budget": "-",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.6718,
                        "n": 262,
                        "std": 0.4705
                    },
                    "test": {
                        "score": 0.6645,
                        "n": 2355,
                        "std": 0.4723
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.7375,
                        "n": 259,
                        "std": 0.4409
                    },
                    "test": {
                        "score": 0.7052,
                        "n": 2330,
                        "std": 0.4561
                    }
                }
            },
            "extras": null
        },
        {
            "model_id": "gslm23c",
            "submission_id": "pGSLM_cont",
            "index": 2,
            "submission_date": "2023-02-24T14:03:41.904297",
            "submitted_by": "admin",
            "description": "HuBert + Kmeans + MS-TLM (unit + f0 + duration) with continuous prosody. Pseudo-probability on unit only. \nRefer to de Seyssel et al (2023) for more details. \nModel used from : E. Kharitonov, A. Lee, A. Polyak, Y. Adi, J. Copet, K. Lakhotia, T. A. Nguyen, M. Riviere, A. Mohamed, E. Dupoux et al., \n\u201cText-free prosody-aware generative spoken language modeling,\u201din Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 8666\u20138681\n",
            "publication": {
                "author_short": "pGSLM continuous",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "LibriLight clean 6k",
                "benchmarks": [],
                "gpu_budget": "-",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.6565,
                        "n": 262,
                        "std": 0.4758
                    },
                    "test": {
                        "score": 0.6679,
                        "n": 2355,
                        "std": 0.4711
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.7375,
                        "n": 259,
                        "std": 0.4409
                    },
                    "test": {
                        "score": 0.715,
                        "n": 2330,
                        "std": 0.4515
                    }
                }
            },
            "extras": null
        },
        {
            "model_id": "gslm23d",
            "submission_id": "pGSLM_cont+shift",
            "index": 3,
            "submission_date": "2023-02-24T14:03:42.049097",
            "submitted_by": "admin",
            "description": "HuBert + Kmeans + MS-TLM (unit + f0 + duration) with continuous prosody and prosodic shift. Pseudo-probability on unit only.\nRefer to de Seyssel et al (2023) for more details. \nModel used from : E. Kharitonov, A. Lee, A. Polyak, Y. Adi, J. Copet, K. Lakhotia, T. A. Nguyen, M. Riviere, A. Mohamed, E. Dupoux et al., \n\u201cText-free prosody-aware generative spoken language modeling,\u201din Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 8666\u20138681\n",
            "publication": {
                "author_short": "pGSLM continuous + prosodic shift",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "LibriLight clean 6k",
                "benchmarks": [],
                "gpu_budget": "-",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.6908,
                        "n": 262,
                        "std": 0.463
                    },
                    "test": {
                        "score": 0.6675,
                        "n": 2355,
                        "std": 0.4712
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.749,
                        "n": 259,
                        "std": 0.4344
                    },
                    "test": {
                        "score": 0.7189,
                        "n": 2330,
                        "std": 0.4496
                    }
                }
            },
            "extras": null
        },
        {
            "model_id": "gslm23e",
            "submission_id": "pGSLM_disc",
            "index": 4,
            "submission_date": "2023-02-24T14:03:42.157234",
            "submitted_by": "admin",
            "description": "HuBert + Kmeans + MS-TLM (unit + f0 + duration) with discrete prosody. Pseudo-probability on unit only.\nRefer to de Seyssel et al (2023) for more details. \nModel used from : E. Kharitonov, A. Lee, A. Polyak, Y. Adi, J. Copet, K. Lakhotia, T. A. Nguyen, M. Riviere, A. Mohamed, E. Dupoux et al., \n\u201cText-free prosody-aware generative spoken language modeling,\u201din Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 8666\u20138681\n",
            "publication": {
                "author_short": "pGSLM discrete",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "LibriLight clean 6k",
                "benchmarks": [],
                "gpu_budget": "-",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.6756,
                        "n": 262,
                        "std": 0.4691
                    },
                    "test": {
                        "score": 0.6476,
                        "n": 2355,
                        "std": 0.4778
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.7452,
                        "n": 259,
                        "std": 0.4366
                    },
                    "test": {
                        "score": 0.7107,
                        "n": 2330,
                        "std": 0.4535
                    }
                }
            },
            "extras": null
        },
        {
            "model_id": "gslm23f",
            "submission_id": "pGSLM_disc+shift",
            "index": 5,
            "submission_date": "2023-02-24T14:03:42.274438",
            "submitted_by": "admin",
            "description": "HuBert + Kmeans + MS-TLM (unit + f0 + duration) with discrete prosody and prosodic shift. Pseudo-probability on unit only.\nRefer to de Seyssel et al (2023) for more details. \nModel used from : E. Kharitonov, A. Lee, A. Polyak, Y. Adi, J. Copet, K. Lakhotia, T. A. Nguyen, M. Riviere, A. Mohamed, E. Dupoux et al., \n\u201cText-free prosody-aware generative spoken language modeling,\u201din Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2022, pp. 8666\u20138681\n",
            "publication": {
                "author_short": "pGSLM discrete + prosodic shift",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "LibriLight clean 6k",
                "benchmarks": [],
                "gpu_budget": "-",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.6908,
                        "n": 262,
                        "std": 0.463
                    },
                    "test": {
                        "score": 0.6594,
                        "n": 2355,
                        "std": 0.474
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.7259,
                        "n": 259,
                        "std": 0.4469
                    },
                    "test": {
                        "score": 0.7288,
                        "n": 2330,
                        "std": 0.4447
                    }
                }
            },
            "extras": null
        },
        {
            "model_id": "gslm23g",
            "submission_id": "STELA_EN_3200",
            "index": 6,
            "submission_date": "2023-02-24T14:03:42.428612",
            "submitted_by": "admin",
            "description": "CPC + Kmeans50 + LSTM.\nRefer to de Seyssel et al (2023) for more details. \nModel first presented in : Lavechin, M., de Seyssel, M., Titeux, H., Bredin, H., Wisniewski, G., Cristia, A., & Dupoux, E. (2022). \nStatistical learning bootstraps early language acquisition.\n",
            "publication": {
                "author_short": "STELA",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "English Audiobooks 3200h",
                "benchmarks": [],
                "gpu_budget": "60",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.7252,
                        "n": 262,
                        "std": 0.4473
                    },
                    "test": {
                        "score": 0.7486,
                        "n": 2355,
                        "std": 0.4339
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.6873,
                        "n": 259,
                        "std": 0.4645
                    },
                    "test": {
                        "score": 0.6828,
                        "n": 2330,
                        "std": 0.4655
                    }
                }
            },
            "extras": null
        },
        {
            "model_id": "gslm23h",
            "submission_id": "STELA_EN_3200_dedup",
            "index": 7,
            "submission_date": "2023-02-24T14:03:42.612164",
            "submitted_by": "admin",
            "description": "CPC + Kmeans50 (deduplicated) + LSTM.\nRefer to de Seyssel et al (2023) for more details. \n",
            "publication": {
                "author_short": "STELA dedup",
                "authors": "Maureen de Seyssel, Andrea Santos, Marvin Lavechin, Hadrien Titeux, Gwendal Virlet, Arthur Thomas, Guillaume Wisniewski, Bogdan Ludusan, Emmanuel Dupoux",
                "paper_title": "ProsAudit, a prosodic benchmark for self-supervised speech models",
                "paper_ref": "https://arxiv.org/abs/2302.12057",
                "bib_ref": null,
                "paper_url": "https://arxiv.org/abs/2302.12057",
                "pub_year": 2023,
                "team_name": "CoML Team",
                "institution": "EHESS, ENS, PSL Research Univerity, CNRS and Inria",
                "code": null,
                "DOI": null,
                "open_science": true
            },
            "details": {
                "train_set": "English Audiobooks 3200h",
                "benchmarks": [],
                "gpu_budget": "60",
                "parameters": {}
            },
            "scores": {
                "protosyntax": {
                    "dev": {
                        "score": 0.5802,
                        "n": 262,
                        "std": 0.4945
                    },
                    "test": {
                        "score": 0.5851,
                        "n": 2355,
                        "std": 0.4928
                    }
                },
                "lexical": {
                    "dev": {
                        "score": 0.4865,
                        "n": 259,
                        "std": 0.5008
                    },
                    "test": {
                        "score": 0.467,
                        "n": 2330,
                        "std": 0.499
                    }
                }
            },
            "extras": null
        }
    ]
}